import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Embedding, Input,Concatenate, Reshape, concatenate
from keras.layers import Flatten,  MaxPooling2D, Conv2D
from keras.callbacks import TensorBoard
from keras.models import Model
import pandas as pd
import numpy as np
from keras.layers import add, BatchNormalization
import time
from keras.optimizers import SGD
from sklearn.preprocessing import MinMaxScaler
import math 
from keras.utils import to_categorical
from sklearn.metrics import accuracy_score, roc_auc_score	
from keras import regularizers
import os

from sklearn.metrics import roc_auc_score
import tensorflow as tf

from sklearn.datasets import make_classification

from keras.utils import np_utils
from keras.callbacks import Callback, EarlyStopping
import gc

init_g = tf.global_variables_initializer()
init_l = tf.local_variables_initializer()
with tf.Session() as sess:
	sess.run(init_g)
	sess.run(init_l)
#init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())
#sess.run(init)

start_time = time.clock()

print("Reading in train data")

dtypes={'MachineIdentifier':'category','ProductName':'category','EngineVersion':'category','AppVersion':'category','AvSigVersion':'category','IsBeta':'int8','RtpStateBitfield':'float16','IsSxsPassiveMode':'int8','DefaultBrowsersIdentifier':'float32','AVProductStatesIdentifier':'float32','AVProductsInstalled':'float16','AVProductsEnabled':'float16','HasTpm':'int8','CountryIdentifier':'int16','CityIdentifier':'float32','OrganizationIdentifier':'float16','GeoNameIdentifier':'float16','LocaleEnglishNameIdentifier':'int16','Platform':'category','Processor':'category','OsVer':'category','OsBuild':'int16','OsSuite':'int16','OsPlatformSubRelease':'category','OsBuildLab':'category','SkuEdition':'category','IsProtected':'float16','AutoSampleOptIn':'int8','PuaMode':'category','SMode':'float16','IeVerIdentifier':'float16','SmartScreen':'category','Firewall':'float16','UacLuaenable':'float32','UacLuaenable':'float64','Census_MDC2FormFactor':'category','Census_DeviceFamily':'category','Census_OEMNameIdentifier':'float32','Census_OEMModelIdentifier':'float32','Census_ProcessorCoreCount':'float16','Census_ProcessorManufacturerIdentifier':'float16','Census_ProcessorModelIdentifier':'float32','Census_ProcessorClass':'category','Census_PrimaryDiskTotalCapacity':'float64','Census_PrimaryDiskTypeName':'category','Census_SystemVolumeTotalCapacity':'float64','Census_HasOpticalDiskDrive':'int8','Census_TotalPhysicalRAM':'float32','Census_ChassisTypeName':'category','Census_InternalPrimaryDiagonalDisplaySizeInInches':'float32','Census_InternalPrimaryDisplayResolutionHorizontal':'float32','Census_InternalPrimaryDisplayResolutionVertical':'float32','Census_PowerPlatformRoleName':'category','Census_InternalBatteryType':'category','Census_InternalBatteryNumberOfCharges':'float64','Census_OSVersion':'category','Census_OSArchitecture':'category','Census_OSBranch':'category','Census_OSBuildNumber':'int16','Census_OSBuildRevision':'int32','Census_OSEdition':'category','Census_OSSkuName':'category','Census_OSInstallTypeName':'category','Census_OSInstallLanguageIdentifier':'float16','Census_OSUILocaleIdentifier':'int16','Census_OSWUAutoUpdateOptionsName':'category','Census_IsPortableOperatingSystem':'int8','Census_GenuineStateName':'category','Census_ActivationChannel':'category','Census_IsFlightingInternal':'float16','Census_IsFlightsDisabled':'float16','Census_FlightRing':'category','Census_ThresholdOptIn':'float16','Census_FirmwareManufacturerIdentifier':'float16','Census_FirmwareVersionIdentifier':'float32','Census_IsSecureBootEnabled':'int8','Census_IsWIMBootEnabled':'float16','Census_IsVirtualDevice':'float16','Census_IsTouchEnabled':'int8','Census_IsPenCapable':'int8','Census_IsAlwaysOnAlwaysConnectedCapable':'float16','Wdft_IsGamer':'float16','Wdft_RegionIdentifier':'float16','HasDetections':'int8'}

train = pd.read_csv('C:/Users/Nick/Desktop/microsoft-malware-prediction/train.csv', dtype = dtypes)
end_time_train_data = time.clock()
print("Time to read in train data", time.clock() - start_time	)
test = pd.read_csv('C:/Users/Nick/Desktop/microsoft-malware-prediction/test.csv', dtype = dtypes)
machine_labels_test = test['MachineIdentifier']
end_time_test_data = time.clock()
print("Time to read in test data", end_time_test_data - end_time_train_data	)

print("the original shape of the training data is: ", train.shape)

del train["MachineIdentifier"], #train["PuaMode"], train["Census_IsWIMBootEnabled"]#, train["DefaultBrowsersIdentifier "]

del test["MachineIdentifier"],# test["PuaMode"], test["Census_IsWIMBootEnabled"]#, test["DefaultBrowsersIdentifier "]

categoricals = list(train.select_dtypes(include = "category").columns)
print(categoricals)

inputs = []
embeddings = []

#build embedding network
for categorical in categoricals :

	#print(categorical)
	cat = Input(shape=(1,))

	vocab = pd.concat([train[categorical], test[categorical]]).nunique() + 1

	embedding_size = int(min(np.ceil((pd.concat([train[categorical], test[categorical]]).nunique() )/2), 50 ))
	
	embedding = Embedding(vocab, embedding_size, input_length=1)(cat)
	embedding = Reshape(target_shape=(embedding_size,))(embedding)
	inputs.append(cat)
	embeddings.append(embedding)

	#This explains the divided by 2 and 50. Used to set the embedding size
	#https://towardsdatascience.com/decoded-entity-embeddings-of-categorical-variables-in-neural-networks-1d2468311635

input_numeric = Input(shape=(52,))
embedding_numeric = Dense(128)(input_numeric) 
inputs.append(input_numeric)
embeddings.append(embedding_numeric)

#ttps://www.kaggle.com/aquatic/entity-embedding-neural-net

x = Concatenate()(embeddings)

x = Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)
x = Dropout(.4)(x)
x = keras.layers.BatchNormalization()(x)
x = Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x) #, kernel_regularizer=regularizers.l2(0.01)
x = Dropout(.4)(x)
x = keras.layers.BatchNormalization()(x)
x = Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)
x = Dropout(.4)(x)
x = keras.layers.BatchNormalization()(x)

output = Dense(1, activation='sigmoid')(x)
model = Model(inputs, output)

#%% Some helper function
def my_metric_func(y_true, y_pred):
    try:
        score = roc_auc_score(y_true, y_pred)
    except:
        score = 0.5
    return score

def nick_auc(y_true, y_pred):
    return tf.py_func(my_metric_func, (y_true, y_pred), tf.double)

adam = keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)
model.compile(loss='binary_crossentropy', optimizer= adam, metrics = [nick_auc])

#now we need to preprocess the data. Everything above has been to define the structure of the NN
#model.summary()

train_rows = int(train.shape[0]*.8)
train_y = train.iloc[0:train_rows,-1]
train_x = train.iloc[0:train_rows,0:-1]

val_y = train.iloc[train_rows:train.shape[0],-1]
val_x = train.iloc[train_rows:train.shape[0],0:-1]

print(train.head())
print(train_y)

### THE SHUFFLING DOES NOT FKING WORK
# Shuffle data

idx = np.arange(len(train_x))
np.random.shuffle(idx)
train_x = train_x.iloc[idx]
train_y = train_y.iloc[idx]

idx = np.arange(len(test))

print('shape of test: ', test.shape)

preproc_train_x = []
preproc_val_x = []
preproc_test = []

for c in categoricals:
	#print(c)
	raw_vals = pd.concat([train[c], test[c]]).unique()
	val_map = {}
	for i in range(len(raw_vals)):
		val_map[raw_vals[i]] = i 

	if np.std(train_x[c].map(val_map).values) != 0:
		train_cat_values = (train_x[c].map(val_map).values - np.mean(train_x[c].map(val_map).values)) / np.std(train_x[c].map(val_map).values)
	
	if np.std(val_x[c].map(val_map).values) != 0:
		val_cat_values = (val_x[c].map(val_map).values - np.mean(val_x[c].map(val_map).values)) / np.std(val_x[c].map(val_map).values)
	
	if np.std(test[c].map(val_map).values) != 0:
		test_cat_values = (test[c].map(val_map).values - np.mean(test[c].map(val_map).values)) / np.std(test[c].map(val_map).values)

	#print(normed_cat_values)
	preproc_train_x.append(train_cat_values)
	preproc_val_x.append(val_cat_values)
	preproc_test.append(test_cat_values)

other_cols = [c for c in train_x.columns if (not c in categoricals)]

preproc_train_x.append(train_x[other_cols].values)
preproc_val_x.append(val_x[other_cols].values)
preproc_test.append(test[other_cols].values)

for i in range(preproc_train_x[29].shape[1]):
	avg_train = np.nanmean(preproc_train_x[29][:,i])
	avg_val = np.nanmean(preproc_val_x[29][:,i])
	avg_test = np.nanmean(preproc_test[29][:,i])
	print(avg_train	)
	preproc_train_x[29][:,i][np.isnan(preproc_train_x[29][:,i])] = avg_train
	preproc_val_x[29][:,i][np.isnan(preproc_val_x[29][:,i])] = avg_val
	preproc_test[29][:,i][np.isnan(preproc_test[29][:,i])] = avg_test

	if np.std(preproc_train_x[29][:,i]) != 0:
		preproc_train_x[29][:,i] = (preproc_train_x[29][:,i]  - np.mean(preproc_train_x[29][:,i])) / np.std(preproc_train_x[29][:,i])

	if np.std(preproc_val_x[29][:,i]) != 0:	
		preproc_val_x[29][:,i] = (preproc_val_x[29][:,i] - np.mean(preproc_val_x[29][:,i])) / np.std(preproc_val_x[29][:,i])

	if np.std(preproc_test[29][:,i]) != 0:	
		preproc_test[29][:,i] = (preproc_test[29][:,i] - np.mean(preproc_test[29][:,i])) / np.std(preproc_test[29][:,i])

my_callbacks = [EarlyStopping(monitor='nick_auc', patience = 5, verbose=1, mode='max')]

gc.collect()

model.fit(preproc_train_x,train_y.values, epochs=30, batch_size = 1000	)#callbacks	= my_callbacks

preds = pd.DataFrame()

preds['MachineIdentifier'] = machine_labels_test

val_preds = model.predict(preproc_val_x)

print("roc auc score:" , roc_auc_score(val_y.values, val_preds))

test_preds = model.predict(preproc_test)

preds['HasDetections'] = test_preds

preds.to_csv('C:/Users/Nick/Desktop/microsoft-malware-prediction/preds_use1.csv', columns = ['MachineIdentifier','HasDetections'], index=False)

'''
while True:

	try:

		file_list = os.listdir('C:/Users/Nick/Desktop/microsoft-malware-prediction')

		randint = np.random.randint(0)

		new_filename = 'C:/Users/Nick/Desktop/microsoft-malware-prediction/preds' + randint + '.csv'

		if new_filename not in file_list:
			preds.to_csv(new_filename , columns = ['MachineIdentifier','HasDetections'], index=False)
			break
'''
